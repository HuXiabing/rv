{
    "model_type": "transformer",
    "max_instr_length": 20,
    "max_instr_count": 20,
    "vocab_size": 2000,
    "embed_dim": 128,
    "hidden_dim": 256,
    "num_layers": 4,
    "num_heads": 8,
    "dropout": 0.1,
    "lr": 0.0001,
    "weight_decay": 1e-05,
    "batch_size": 32,
    "epochs": 10,
    "patience": 5,
    "clip_grad_norm": 1.0,
    "device": "cuda",
    "raw_data_path": "data/labeled_data.json",
    "processed_data_path": "data/processed_data.json",
    "train_data_path": "data/train_data.h5",
    "val_data_path": "data/val_data.h5",
    "test_data_path": "data/test_data.h5",
    "output_dir": "experiments/transformer_v1_20250303_153305",
    "experiment_name": "transformer_v1",
    "experiment_dir": "experiments/transformer_v1_20250303_153305/transformer_v1",
    "checkpoint_dir": "experiments/transformer_v1_20250303_153305/transformer_v1/checkpoints",
    "log_dir": "experiments/transformer_v1_20250303_153305/transformer_v1/logs",
    "vocab_path": "experiments/transformer_v1_20250303_153305/transformer_v1/vocab.json",
    "seed": 42,
    "verbose": true,
    "save_best_only": true,
    "save_freq": 1,
    "max_checkpoints": 3,
    "loss_type": "mape",
    "loss_epsilon": 1e-05,
    "huber_delta": 1.0,
    "use_layernorm": true,
    "use_checkpoint": false,
    "use_bb_attn": true,
    "use_seq_attn": true,
    "use_op_attn": true,
    "use_pos_2d": false,
    "handle_neg": false,
    "optimizer": "adamw",
    "scheduler": "plateau",
    "use_experiment_manager": false
}